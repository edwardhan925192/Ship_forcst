# -*- coding: utf-8 -*-
"""data_prep.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10pXbR8tsZJSPp24FTWdoBvm5CRIHjKzs
"""

import pandas as pd
from tqdm import tqdm

def preprocess(df):
    # Identify rows that meet the condition
    rows_to_remove = df[(df['DIST'] == 0)].index

    # Dropping rows that have 0 distances
    df = df.drop(rows_to_remove, axis=0)

    # Resetting index
    df = df.reset_index(drop=True)

    return df

def extract_date_parts(df, datetime_col):

    # Ensure the column is in datetime format
    df[datetime_col] = pd.to_datetime(df[datetime_col])

    # Extract year, month, and day
    df['year'] = df[datetime_col].dt.year
    df['month'] = df[datetime_col].dt.month
    df['day'] = df[datetime_col].dt.day
    df['hour'] = df[datetime_col].dt.hour
    df = df.drop([datetime_col],axis = 1)

    return df

def previous_delays(df, num_instances=2):

    # Convert year, month, day columns to a single datetime column for easier date manipulations
    df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])

    # The function that will be applied to each group
    def process_group(group):
        group = group.sort_values(by=['datetime'])

        # This column will store the calculated CI_HOUR values
        new_values = []

        for idx, row in tqdm(group.iterrows(), total=group.shape[0], desc="Processing group"):
            # Find all previous rows before the current row's time
            previous_rows = group[group['datetime'] < row['datetime']]

            # Check if there are at least 'num_instances' previous rows
            if previous_rows.shape[0] >= num_instances:
                # Get the CI_HOUR value from the 'num_instances'-th previous entry
                value = previous_rows.iloc[-num_instances]['CI_HOUR']
                new_values.append(value)
            else:
                new_values.append(row['CI_HOUR'])  # If not enough previous rows, keep original value

        group['CI_HOUR'] = new_values
        return group

    # Group by 'ARI_CO' and apply the processing function
    df = df.groupby('ARI_CO').progress_apply(process_group).reset_index(drop=True)  # Added tqdm for progress_apply

    # Drop the auxiliary datetime column
    df = df.drop(columns=['datetime'])

    return df